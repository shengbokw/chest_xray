{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage import morphology, io, exposure, img_as_float, transform, img_as_ubyte\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataGeneral(df, path, im_shape):\n",
    "    \"\"\"\n",
    "    reshaping images\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    for i, item in df.iterrows():\n",
    "        img = img_as_float(io.imread(path + '/' + item[0]))\n",
    "        img = transform.resize(img, im_shape)\n",
    "        img = exposure.equalize_hist(img)\n",
    "        img = np.expand_dims(img, -1)\n",
    "        X.append(img)\n",
    "\n",
    "    X = np.array(X)\n",
    "    X -= X.mean()\n",
    "    X /= X.std()\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_small_regions(img, size):\n",
    "    \"\"\"\n",
    "    Morphologically removes small (less than size)\n",
    "    connected regions of 0s or 1s.\n",
    "    \"\"\"\n",
    "    img = morphology.remove_small_objects(img, size)\n",
    "    img = morphology.remove_small_holes(img, size)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution(gray_img):\n",
    "    \"\"\"\n",
    "    calculate the distribution of img,\n",
    "    total will be used on calculating fraction\n",
    "    \"\"\"\n",
    "    img_shape = gray_img.shape\n",
    "    # changed gray scale value into 0-16\n",
    "    gray_distribution = [0] * 16\n",
    "    total = 0\n",
    "    for i in range(0, img_shape[0]):\n",
    "        for j in range(0, img_shape[1]):\n",
    "            gray_distribution[int(gray_img[i][j])] += 1\n",
    "            total += int(gray_img[i][j])\n",
    "\n",
    "    return gray_distribution, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lung_density(pr, img):\n",
    "    \"\"\"calculate the density of two lungs.\"\"\"\n",
    "    density = 0\n",
    "    size = 0\n",
    "    img_shape = img.shape\n",
    "    for i in range(0, img_shape[0]):\n",
    "        for j in range(0, img_shape[1]):\n",
    "            if pr[i][j] == 1:\n",
    "                size += 1\n",
    "                density += img[i][j]\n",
    "\n",
    "    return density * 1.0 / (size + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_of_lungs(img):\n",
    "    # img = read_the_image_file()\n",
    "    t = [[img[j][i] for j in range(len(img))] for i in range(len(img[0]))]\n",
    "    r = 0  # right (in actual body) lung\n",
    "    l = 0\n",
    "    s = 0  # starting point\n",
    "    m = 0  # middle_separation point\n",
    "    for line in range(len(t)):\n",
    "        if sum(t[line][:]) > 0:\n",
    "            s = line\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "    for line in range(s, len(t)):\n",
    "        if sum(t[line][:]) == 0:\n",
    "            m = line\n",
    "            break\n",
    "        else:\n",
    "            s_r = sum(t[line][:])\n",
    "            r = r + s_r\n",
    "    for line in range(m, len(t)):\n",
    "        s_l = sum(t[line][:])\n",
    "        l = l + s_l\n",
    "\n",
    "    fraction = round(l/r, 3)\n",
    "    # print(\"Right lung: %s\" % r, \"\\nLeft lung size: %s\" % l, \"\\nFraction between right and left lung: %s\" % fraction)\n",
    "\n",
    "    return r, l, fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(model, folder, df, savefile):\n",
    "    \"\"\"\n",
    "    this function will combine features:\n",
    "    gray scale value distribution,\n",
    "    density of lungs,\n",
    "    ...\n",
    "    \"\"\"\n",
    "    features = []\n",
    "\n",
    "    # Load test data\n",
    "    im_shape = (256, 256)\n",
    "    X = loadDataGeneral(df, folder, im_shape)\n",
    "\n",
    "    # stop when it arrive the length of X\n",
    "    n_test = X.shape[0]\n",
    "    inp_shape = X[0].shape\n",
    "\n",
    "    # Load model\n",
    "    UNet = load_model(model)\n",
    "\n",
    "    # For inference standard keras ImageGenerator can be used.\n",
    "    test_gen = ImageDataGenerator(rescale=1.)\n",
    "\n",
    "    i = 0\n",
    "    for xx in test_gen.flow(X, batch_size=1):\n",
    "        # feature = []\n",
    "        img = exposure.rescale_intensity(np.squeeze(xx), out_range=(0, 1))\n",
    "        # I'm still thinking about how to deal with the gray scale\n",
    "        # img = img_as_ubyte(img)\n",
    "        # convert image gray scale into 0-16\n",
    "        img = img * 15\n",
    "        img = img.astype(dtype=np.int8)\n",
    "        pred = UNet.predict(xx)[..., 0].reshape(inp_shape[:2])\n",
    "        pr = pred > 0.5\n",
    "        pr = remove_small_regions(pr, 0.02 * np.prod(im_shape))\n",
    "        pr_int = np.array(pr, dtype=np.int8)\n",
    "\n",
    "        dist, total = distribution(img)\n",
    "        dist.append(total)\n",
    "        dist.append(lung_density(pr_int, img))\n",
    "        r, l, fraction = size_of_lungs(pr_int)\n",
    "        dist.append(r)\n",
    "        dist.append(l)\n",
    "        dist.append(fraction)\n",
    "\n",
    "        features.append(dist)\n",
    "        # np.savetxt('test.out', pr_int, delimiter='', fmt=\"%s\")\n",
    "\n",
    "        i += 1\n",
    "        if i == n_test:\n",
    "            break\n",
    "\n",
    "    np_features = np.array(features)\n",
    "    np.savetxt(savefile, np_features, delimiter=',', fmt=\"%s\")\n",
    "    # return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features from normal\n",
    "model = '/Users/shengbo/shengbo/VU/ML/chest_xray/lung-segmentation-2d/trained_model.hdf5'\n",
    "folder = '/Users/shengbo/shengbo/VU/ML/chest_xray/val/NORMAL'\n",
    "files = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "df = pd.DataFrame(data=files, columns={'img'})\n",
    "df[df['img'] == '.DS_Store'] = None\n",
    "df = df.dropna()\n",
    "extract_features(model, folder, df, 'normal_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features from pneumonia\n",
    "model = '/Users/shengbo/shengbo/VU/ML/chest_xray/lung-segmentation-2d/trained_model.hdf5'\n",
    "folder = '/Users/shengbo/shengbo/VU/ML/chest_xray/val/PNEUMONIA'\n",
    "files = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "df = pd.DataFrame(data=files, columns={'img'})\n",
    "df[df['img'] == '.DS_Store'] = None\n",
    "df = df.dropna()\n",
    "extract_features(model, folder, df, 'pneumonia_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = '/Users/shengbo/shengbo/VU/ML/chest_xray/lung-segmentation-2d/trained_model.hdf5'\n",
    "folder = '/Users/shengbo/shengbo/VU/ML/chest_xray/test/NORMAL'\n",
    "files = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "df = pd.DataFrame(data=files, columns={'img'})\n",
    "df[df['img'] == '.DS_Store'] = None\n",
    "df = df.dropna()\n",
    "extract_features(model, folder, df, 'normal_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nor_df = pd.read_csv('normal_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>11784.0</th>\n",
       "      <th>3812.0</th>\n",
       "      <th>3813.0</th>\n",
       "      <th>3801.0</th>\n",
       "      <th>3837.0</th>\n",
       "      <th>3815.0</th>\n",
       "      <th>3819.0</th>\n",
       "      <th>3853.0</th>\n",
       "      <th>3783.0</th>\n",
       "      <th>3849.0</th>\n",
       "      <th>...</th>\n",
       "      <th>3799.0</th>\n",
       "      <th>3786.0</th>\n",
       "      <th>3903.0</th>\n",
       "      <th>4038.0</th>\n",
       "      <th>13.0</th>\n",
       "      <th>405051.0</th>\n",
       "      <th>3.4634116718285055</th>\n",
       "      <th>10035.0</th>\n",
       "      <th>6431.0</th>\n",
       "      <th>0.641</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11032.0</td>\n",
       "      <td>3842.0</td>\n",
       "      <td>3847.0</td>\n",
       "      <td>3883.0</td>\n",
       "      <td>3847.0</td>\n",
       "      <td>3854.0</td>\n",
       "      <td>3834.0</td>\n",
       "      <td>3879.0</td>\n",
       "      <td>3829.0</td>\n",
       "      <td>3921.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3831.0</td>\n",
       "      <td>3943.0</td>\n",
       "      <td>3774.0</td>\n",
       "      <td>4384.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>412376.0</td>\n",
       "      <td>4.778062</td>\n",
       "      <td>7816.0</td>\n",
       "      <td>5867.0</td>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10313.0</td>\n",
       "      <td>3889.0</td>\n",
       "      <td>3917.0</td>\n",
       "      <td>3919.0</td>\n",
       "      <td>3942.0</td>\n",
       "      <td>3899.0</td>\n",
       "      <td>3927.0</td>\n",
       "      <td>3876.0</td>\n",
       "      <td>3965.0</td>\n",
       "      <td>3903.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3821.0</td>\n",
       "      <td>4092.0</td>\n",
       "      <td>3992.0</td>\n",
       "      <td>4132.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>416968.0</td>\n",
       "      <td>4.522282</td>\n",
       "      <td>8764.0</td>\n",
       "      <td>6449.0</td>\n",
       "      <td>0.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10724.0</td>\n",
       "      <td>3937.0</td>\n",
       "      <td>3903.0</td>\n",
       "      <td>3882.0</td>\n",
       "      <td>3905.0</td>\n",
       "      <td>3888.0</td>\n",
       "      <td>3901.0</td>\n",
       "      <td>3922.0</td>\n",
       "      <td>3876.0</td>\n",
       "      <td>3852.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3931.0</td>\n",
       "      <td>3913.0</td>\n",
       "      <td>3972.0</td>\n",
       "      <td>4019.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>412249.0</td>\n",
       "      <td>5.565868</td>\n",
       "      <td>7196.0</td>\n",
       "      <td>4903.0</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9273.0</td>\n",
       "      <td>3985.0</td>\n",
       "      <td>3951.0</td>\n",
       "      <td>4004.0</td>\n",
       "      <td>4019.0</td>\n",
       "      <td>3985.0</td>\n",
       "      <td>3987.0</td>\n",
       "      <td>4021.0</td>\n",
       "      <td>3968.0</td>\n",
       "      <td>3967.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4029.0</td>\n",
       "      <td>3906.0</td>\n",
       "      <td>4038.0</td>\n",
       "      <td>4298.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>424693.0</td>\n",
       "      <td>4.839244</td>\n",
       "      <td>8599.0</td>\n",
       "      <td>6062.0</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9871.0</td>\n",
       "      <td>3918.0</td>\n",
       "      <td>3927.0</td>\n",
       "      <td>3967.0</td>\n",
       "      <td>3921.0</td>\n",
       "      <td>3991.0</td>\n",
       "      <td>3930.0</td>\n",
       "      <td>3944.0</td>\n",
       "      <td>3934.0</td>\n",
       "      <td>3914.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4078.0</td>\n",
       "      <td>4075.0</td>\n",
       "      <td>3975.0</td>\n",
       "      <td>4146.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>420355.0</td>\n",
       "      <td>4.429941</td>\n",
       "      <td>9545.0</td>\n",
       "      <td>6205.0</td>\n",
       "      <td>0.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9425.0</td>\n",
       "      <td>3973.0</td>\n",
       "      <td>3943.0</td>\n",
       "      <td>4018.0</td>\n",
       "      <td>3963.0</td>\n",
       "      <td>4012.0</td>\n",
       "      <td>3998.0</td>\n",
       "      <td>3992.0</td>\n",
       "      <td>4084.0</td>\n",
       "      <td>3989.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4017.0</td>\n",
       "      <td>4027.0</td>\n",
       "      <td>4011.0</td>\n",
       "      <td>4082.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>422267.0</td>\n",
       "      <td>3.899186</td>\n",
       "      <td>11070.0</td>\n",
       "      <td>8351.0</td>\n",
       "      <td>0.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4078.0</td>\n",
       "      <td>4674.0</td>\n",
       "      <td>4311.0</td>\n",
       "      <td>4394.0</td>\n",
       "      <td>4346.0</td>\n",
       "      <td>4333.0</td>\n",
       "      <td>4350.0</td>\n",
       "      <td>4291.0</td>\n",
       "      <td>4336.0</td>\n",
       "      <td>4301.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4293.0</td>\n",
       "      <td>4319.0</td>\n",
       "      <td>4392.0</td>\n",
       "      <td>4844.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>461774.0</td>\n",
       "      <td>6.848019</td>\n",
       "      <td>8272.0</td>\n",
       "      <td>4597.0</td>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   11784.0  3812.0  3813.0  3801.0  3837.0  3815.0  3819.0  3853.0  3783.0  \\\n",
       "0  11032.0  3842.0  3847.0  3883.0  3847.0  3854.0  3834.0  3879.0  3829.0   \n",
       "1  10313.0  3889.0  3917.0  3919.0  3942.0  3899.0  3927.0  3876.0  3965.0   \n",
       "2  10724.0  3937.0  3903.0  3882.0  3905.0  3888.0  3901.0  3922.0  3876.0   \n",
       "3   9273.0  3985.0  3951.0  4004.0  4019.0  3985.0  3987.0  4021.0  3968.0   \n",
       "4   9871.0  3918.0  3927.0  3967.0  3921.0  3991.0  3930.0  3944.0  3934.0   \n",
       "5   9425.0  3973.0  3943.0  4018.0  3963.0  4012.0  3998.0  3992.0  4084.0   \n",
       "6   4078.0  4674.0  4311.0  4394.0  4346.0  4333.0  4350.0  4291.0  4336.0   \n",
       "\n",
       "   3849.0  ...    3799.0  3786.0  3903.0  4038.0  13.0  405051.0  \\\n",
       "0  3921.0  ...    3831.0  3943.0  3774.0  4384.0  40.0  412376.0   \n",
       "1  3903.0  ...    3821.0  4092.0  3992.0  4132.0  63.0  416968.0   \n",
       "2  3852.0  ...    3931.0  3913.0  3972.0  4019.0  11.0  412249.0   \n",
       "3  3967.0  ...    4029.0  3906.0  4038.0  4298.0  74.0  424693.0   \n",
       "4  3914.0  ...    4078.0  4075.0  3975.0  4146.0  46.0  420355.0   \n",
       "5  3989.0  ...    4017.0  4027.0  4011.0  4082.0  23.0  422267.0   \n",
       "6  4301.0  ...    4293.0  4319.0  4392.0  4844.0   2.0  461774.0   \n",
       "\n",
       "   3.4634116718285055  10035.0  6431.0  0.641  \n",
       "0            4.778062   7816.0  5867.0  0.751  \n",
       "1            4.522282   8764.0  6449.0  0.736  \n",
       "2            5.565868   7196.0  4903.0  0.681  \n",
       "3            4.839244   8599.0  6062.0  0.705  \n",
       "4            4.429941   9545.0  6205.0  0.650  \n",
       "5            3.899186  11070.0  8351.0  0.754  \n",
       "6            6.848019   8272.0  4597.0  0.556  \n",
       "\n",
       "[7 rows x 21 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
